{
  "hash": "ae5b9b00d33d2d176ba17caf038cef86",
  "result": {
    "markdown": "---\ntitle: \"Minimal detectable difference for a time-to-event endpoint in a Phase 3 clinical trial\"\nauthor: \"Kaspar Rufibach, 9th August 2023\"\nexecute:   \n  freeze: auto  # re-render only when source changes\noutput: \n  rmarkdown::html_document:\n    highlight: pygments\n    number_sections: no\n    self_contained: yes\n    toc: yes\n    toc_depth: 3\n    toc_float: yes\n    code_download: true\n---\n\n::: {.cell}\n\n:::\n\n\n# Purpose of this document\n\nThis R markdown file accompanies this [linkedin post](https://www.linkedin.com/posts/kasparrufibach_here-is-a-question-for-anyone-working-on-activity-7094488116748529664-9TYr?utm_source=share&utm_medium=member_desktop), provides the code to reproduce computations, and much more. \n\n# Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# we use rpact for some basic computations\nlibrary(rpact)\n```\n:::\n\n\n# Trial design\n\nFirst, let us specify the basic parameters of a Phase 3 clinical trial with a time-to-event endpoint:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# probability of type I and type II error\nalpha <- 0.05\nbeta <- 0.2\n\n# effect size we target\nhr <- 0.75\n\n# required events for single-stage design, i.e. without interim\nnevent0 <- rpact::getSampleSizeSurvival(hazardRatio = hr, sided = 2, alpha = alpha, beta = beta)\nnevent <- ceiling(nevent0$maxNumberOfEvents)\nnevent \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 380\n```\n:::\n:::\n\n\nSo we plan a trial assuming:\n\n- 1:1 randomization,\n- no interim analyses,\n- 80% power to \n- detect a hazard ratio (HR) of 0.75 \n- using a two-sided logrank test \n- with a significance level of 0.05. \n\nThe number of events needed for these assumptions is then d = 380. Assume we have run the trial and collected these 380 events events in a certain number of patients. The question is:\n\n# Question\n\n**What hazard ratio in favor of the experimental treatment do we need to observe such that we get a one-sided $p$-value of exactly $\\alpha / 2 = 0.025$?**\n\n# Answer\n\nThe answer to the above question is, what I call, the <font color='red'>minimal detectable difference (MDD)</font>. It can be computed in various ways which I all describe below. \n\nNote that we work on the log(HR) scale. This, because the estimate $\\hat \\theta = \\log(\\widehat{\\text{HR}})$ can well be approximated through a Normal distribution according to \n\\begin{eqnarray*}\n\\hat{\\theta} := \\log(\\widehat{\\text{HR}}) &=& N(\\theta, 4 / d).\n\\end{eqnarray*}\n\nwith $\\theta$ the true underlying log hazard ratio and $\\text{SE}(\\hat{\\theta}) = \\sqrt{4 / d}$.\n\n## Critical value of hypothesis test on effect scale\n\nThe MDD is, simply speaking, the critical value of the hypothesis test on the scale of the effect size of interest. So, to find the answer to our question above we simply have to solve\n\\begin{eqnarray*}\n\\frac{\\hat{\\theta}}{\\text{SE}(\\hat{\\theta})} &=& -q_{1 - \\alpha / 2}\n\\end{eqnarray*}\nfor $\\hat \\theta$, giving us \n\\begin{eqnarray*}\n\\hat \\theta &=& -q_{1 - \\alpha / 2} \\text{SE}(\\hat{\\theta})\\Bigr.\n\\end{eqnarray*}\n\nFrom this we get $\\widehat{\\text{HR}} = \\exp(\\hat \\theta)$. Let us verify this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# compute MDD as rescaled critical value of hypothesis test:\nse <- sqrt(4 / nevent)\nmdd <- exp(-qnorm(1 - alpha / 2) * se)\nmdd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8178404\n```\n:::\n\n```{.r .cell-code}\n# one-sided p-value at MDD\npnorm(log(mdd) / se)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.025\n```\n:::\n:::\n\n\n## Value of hazard ratio such that upper end of confidence interval is just at 1\n\nAlternatively, exploiting the connection between hypothesis test and confidence interval, we can find the MDD as the center of a $1 - \\alpha$ confidence interval that has its upper limit exactly at a HR of 1, corresponding to a log(HR) at 0, i.e. we solve\n$$\n\\hat \\theta + q_{1 - \\alpha / 2} \\text{SE}(\\hat{\\theta}) \\ != \\ 0\n$$\nfor $\\hat \\theta$ again giving the same expression as above.\n\n## Pick alternative in sample size formula such that it is centered on the critical value\n\nThe below figure can be used to motivate derivation of a sample size formula assessing \n$$\nH_0 \\ : \\ \\theta = \\theta_0 = 0 \\ \\ \\text{vs.} \\ \\ H_1 \\ : \\ \\theta = \\theta_1 \\ne \\theta_0.\n$$\nThe figure reveals that we precisely get a test for the MDD if we center the alternative at $\\theta_1 =$ MDD, which implies that we can compute the MDD using the usual sample size formula by choosing 50% power.\n\n\n::: {.cell layout-align=\"center\"}\n![](20230809_mdd_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=672}\n:::\n\n\nLet us again verify this: we need to solve the sample size formula of the logrank test for $\\theta$:\n\\begin{eqnarray*}\nd  &=&  \\frac{4(q_{1 - \\alpha / 2} + q_{1 - \\beta})^2}{\\theta^2} \\Leftrightarrow \\\\\n\\theta  &=&  \\pm(q_{1 - \\alpha / 2} + q_{1 - \\beta}) \\sqrt{4 / d} \\ = \\ \\pm q_{1 - \\alpha / 2} \\text{SE}(\\hat{\\theta}).\n\\end{eqnarray*}\nsince $q_{0.5} = 0$. So we end up with the same formula as above.\n\n## Using rpact\n\nFinally, [rpact](https://cran.r-project.org/package=rpact) automatically gives us the critical value on the effect scale:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnevent0$criticalValuesEffectScaleLower[1, 1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8177\n```\n:::\n:::\n\n\n# Some comments\n\nThe critical value of a hypothesis test is derived assuming the null hypothesis is true. As a consequence, the MDD does not need any assumption about exponentiality or proportional hazards. Strictly speaking, an assumption about the alternative comes in through the number of events that are computed (defining $\\text{SE}(\\hat{\\theta})$) making a specific assumption about a treatment effect.\n\n# Clinical implications\n\nSo, let us again recap: \n\n- Our trial has power of 80% at an alternative of HR = 0.75. However, that is a consideration under a specific alternative hypothesis $H_1$.\n- Since the critical value of a hypothesis test is computed assuming the null hypothesis $H_0$ is true, the above consideration does not tell us anything about for which effect size the hypothesis test is statistically significant. Rather, to answer the question about statistical significance we need the critical value of the hypothesis test ($=q_{1 - \\alpha / 2}$) on the effect (= hazard ratio) scale. We call this effect the **minimal detectable difference**. Above I have illustrated several ways to compute this MDD, and in our example it amounts to 0.818.\n\nNow, to me it is somewhat surprising that in clinical trial design focus is so much on the <font color='red'>effect we power at</font>, i.e. the hazard ratio of 0.75 in our example. In my opinion this carries a risk of being misinterpreted in the sense that stakeholders are of the opinion that - if the trial is statistically significant - we will indeed observe a HR of 0.75. However, that is obviously not the case: the trial will also be statistically significant for any final HR estimate in the interval $(0.75, 0.818]$. So, when designing a trial planners should not focus on a discussion of the HR we power at, but rather on the MDD and ask\n\n**Will we change clinical practice if at the end of the trial we observe a hazard ratio of 0.818?**\n\nOtherwise, if stakeholders are of the opinion to \"get\" 0.75 in case of a successful trial there is a risk for disappointment, and even a _statistically significant but clinically irrelevant trial_ in case $\\hat{\\theta} \\in (0.75, 0.818]$.\n\n\n",
    "supporting": [
      "20230809_mdd_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}